{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba08bcb",
   "metadata": {},
   "source": [
    "# Практическая работа №6\n",
    "Необходимо разработать (автономную) диалоговую программную систему или подсистему для программного продукта, создаваемого в рамках магистерского исследования. Например, в формате чат-бота. Рекомендуется использовать результаты, полученные при выполнении предыдущих практических работ. Внимание: допускается использовать любые известные подходы к генерации осмысленных предложений, кроме шаблонного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089350ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc5997",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8a7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lines(path):\n",
    "    lines = {}\n",
    "    with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 5:\n",
    "                lines[parts[0]] = parts[4].lower()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def load_pairs(lines_path, conv_path, limit=1000):\n",
    "    lines = load_lines(lines_path)\n",
    "    pairs = []\n",
    "\n",
    "    with open(conv_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for row in f:\n",
    "            parts = row.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 4:\n",
    "                ids = ast.literal_eval(parts[3])\n",
    "                for i in range(len(ids) - 1):\n",
    "                    if ids[i] in lines and ids[i+1] in lines:\n",
    "                        pairs.append((lines[ids[i]], lines[ids[i+1]]))\n",
    "            if len(pairs) >= limit:\n",
    "                break\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f3942",
   "metadata": {},
   "source": [
    "## Cловарь и токинизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c9ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.replace(\"?\", \"\").replace(\"!\", \"\").replace(\".\", \"\").split()\n",
    "\n",
    "\n",
    "pairs = load_pairs(\"data/movie_lines.txt\", \"data/movie_conversations.txt\")\n",
    "\n",
    "counter = Counter()\n",
    "for q, a in pairs:\n",
    "    counter.update(tokenize(q))\n",
    "    counter.update(tokenize(a))\n",
    "\n",
    "vocab = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\":2, \"<UNK>\":3}\n",
    "for w in counter:\n",
    "    vocab[w] = len(vocab)\n",
    "\n",
    "ivocab = {i:w for w,i in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990739f",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300a19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence):\n",
    "    return [vocab.get(w, vocab[\"<UNK>\"]) for w in tokenize(sentence)]\n",
    "\n",
    "\n",
    "data = []\n",
    "for q, a in pairs:\n",
    "    src = encode(q)\n",
    "    tgt = [vocab[\"<SOS>\"]] + encode(a) + [vocab[\"<EOS>\"]]\n",
    "    data.append((src, tgt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69eed90",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bb3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB = 128\n",
    "HID = 256\n",
    "\n",
    "encoder_emb = nn.Embedding(len(vocab), EMB)\n",
    "encoder = nn.LSTM(EMB, HID, batch_first=True)\n",
    "\n",
    "decoder_emb = nn.Embedding(len(vocab), EMB)\n",
    "decoder = nn.LSTM(EMB, HID, batch_first=True)\n",
    "fc = nn.Linear(HID, len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a075d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=5.8586\n",
      "Epoch 2, loss=4.8555\n",
      "Epoch 3, loss=3.8161\n",
      "Epoch 4, loss=2.5839\n",
      "Epoch 5, loss=1.5493\n",
      "Epoch 6, loss=0.9007\n",
      "Epoch 7, loss=0.5091\n",
      "Epoch 8, loss=0.3037\n",
      "Epoch 9, loss=0.1868\n",
      "Epoch 10, loss=0.1253\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "opt = optim.Adam(\n",
    "    list(encoder.parameters()) +\n",
    "    list(decoder.parameters()) +\n",
    "    list(encoder_emb.parameters()) +\n",
    "    list(decoder_emb.parameters()) +\n",
    "    list(fc.parameters()),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    random.shuffle(data)\n",
    "    for src, tgt in data:\n",
    "        src = torch.tensor(src).unsqueeze(0)\n",
    "        tgt = torch.tensor(tgt).unsqueeze(0)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        enc_out, hidden = encoder(encoder_emb(src))\n",
    "\n",
    "        dec_in = tgt[:, :-1]\n",
    "        dec_out, _ = decoder(decoder_emb(dec_in), hidden)\n",
    "\n",
    "        logits = fc(dec_out)\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt[:, 1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, loss={total_loss/len(data):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cab24e",
   "metadata": {},
   "source": [
    "## Генерация ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba29421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(text, max_len=20, temperature=1.0):\n",
    "    src = torch.tensor(encode(text)).unsqueeze(0)\n",
    "    _, hidden = encoder(encoder_emb(src))\n",
    "\n",
    "    cur = torch.tensor([[vocab[\"<SOS>\"]]])\n",
    "    result = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out, hidden = decoder(decoder_emb(cur), hidden)\n",
    "        logits = fc(out[:, -1]) / temperature\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        if next_token == vocab[\"<EOS>\"]:\n",
    "            break\n",
    "\n",
    "        result.append(ivocab.get(next_token, \"<UNK>\"))\n",
    "        cur = torch.tensor([[next_token]])\n",
    "\n",
    "    return \" \".join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe31e9a",
   "metadata": {},
   "source": [
    "## Чат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cd39d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'exit' - выйти из чата\n",
      "Вы:  hi\n",
      "Бот: looks like things worked out tonight, huh\n",
      "Вы:  i don't know\n",
      "Бот: what i think of it\n",
      "Вы:  tell me\n",
      "Бот: you need therapy has anyone ever told you that\n",
      "Вы:  no\n",
      "Бот: what about back home\n"
     ]
    }
   ],
   "source": [
    "print(\"'exit' - выйти из чата\")\n",
    "while True:\n",
    "    msg = input(\"Вы: \").lower()\n",
    "    if msg == \"exit\":\n",
    "        break\n",
    "    print(\"Вы: \", msg)\n",
    "    print(\"Бот:\", reply(msg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
